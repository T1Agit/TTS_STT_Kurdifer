{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé§ Kurdish TTS Training with Coqui TTS\n",
    "\n",
    "Train a custom Kurdish (Kurmanji) voice model using your own audio samples.\n",
    "\n",
    "## üìã Requirements\n",
    "- Google Colab with GPU (T4 or better)\n",
    "- 30 minutes to 2 hours of Kurdish audio recordings\n",
    "- Corresponding text transcriptions\n",
    "- 2-6 hours for training\n",
    "\n",
    "## üéØ What You'll Build\n",
    "A custom Kurdish text-to-speech model that can:\n",
    "- Speak any Kurdish text in a natural voice\n",
    "- Run on your Raspberry Pi or local server\n",
    "- Generate high-quality audio files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-gpu"
   },
   "source": [
    "## üöÄ Step 1: Check GPU Availability\n",
    "\n",
    "First, verify that you have GPU access. Go to **Runtime ‚Üí Change runtime type** and select **GPU (T4)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Install Coqui TTS and required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-tts"
   },
   "outputs": [],
   "source": [
    "# Install Coqui TTS\n",
    "!pip install -q TTS>=0.27.0\n",
    "!pip install -q pydub librosa soundfile\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare-data-header"
   },
   "source": [
    "## üìÅ Step 3: Prepare Your Training Data\n",
    "\n",
    "### Data Format\n",
    "You need:\n",
    "1. **Audio files**: MP3 or WAV files (16kHz, mono recommended)\n",
    "2. **Metadata file**: CSV or TXT file with audio_file|transcription pairs\n",
    "\n",
    "### Example Directory Structure\n",
    "```\n",
    "kurdish_data/\n",
    "‚îú‚îÄ‚îÄ wavs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ audio_001.wav\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ audio_002.wav\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ metadata.csv\n",
    "```\n",
    "\n",
    "### Example Metadata Format\n",
    "```\n",
    "wavs/audio_001.wav|Silav, tu √ßawa y√Æ?\n",
    "wavs/audio_002.wav|Ez bi x√™r im, spas!\n",
    "wavs/audio_003.wav|Nav√™ min Ahmed e.\n",
    "```\n",
    "\n",
    "### Upload Your Data\n",
    "Upload your audio files and metadata.csv to Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-data"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('kurdish_data/wavs', exist_ok=True)\n",
    "\n",
    "print(\"üì§ Please upload your audio files to kurdish_data/wavs/\")\n",
    "print(\"üì§ Then upload your metadata.csv to kurdish_data/\")\n",
    "print(\"\\nAlternatively, manually upload using the file browser on the left.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocess-header"
   },
   "source": [
    "## üîß Step 4: Preprocess Audio Files\n",
    "\n",
    "Convert audio to the required format (16kHz, mono) and verify the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess-audio"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess_audio(input_path, output_path, target_sr=16000):\n",
    "    \"\"\"Convert audio to 16kHz mono WAV format.\"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        audio, sr = librosa.load(input_path, sr=target_sr, mono=True)\n",
    "        \n",
    "        # Save as WAV\n",
    "        sf.write(output_path, audio, target_sr)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process all audio files\n",
    "wavs_dir = Path('kurdish_data/wavs')\n",
    "processed_dir = Path('kurdish_data/wavs_processed')\n",
    "processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "audio_files = list(wavs_dir.glob('*.wav')) + list(wavs_dir.glob('*.mp3'))\n",
    "print(f\"Found {len(audio_files)} audio files\")\n",
    "\n",
    "successful = 0\n",
    "for audio_file in audio_files:\n",
    "    output_file = processed_dir / f\"{audio_file.stem}.wav\"\n",
    "    if preprocess_audio(audio_file, output_file):\n",
    "        successful += 1\n",
    "        if successful % 100 == 0:\n",
    "            print(f\"Processed {successful}/{len(audio_files)} files...\")\n",
    "\n",
    "print(f\"‚úÖ Successfully preprocessed {successful}/{len(audio_files)} audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-data-header"
   },
   "source": [
    "## ‚úÖ Step 5: Verify Dataset\n",
    "\n",
    "Check the dataset structure and play a sample audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-dataset"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = 'kurdish_data/metadata.csv'\n",
    "\n",
    "if os.path.exists(metadata_path):\n",
    "    # Read metadata\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(f\"üìä Dataset Statistics:\")\n",
    "    print(f\"   Total samples: {len(lines)}\")\n",
    "    \n",
    "    # Calculate total duration\n",
    "    total_duration = 0\n",
    "    for i, line in enumerate(lines[:100]):  # Check first 100 for speed\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) >= 2:\n",
    "            audio_path = f\"kurdish_data/{parts[0]}\"\n",
    "            if os.path.exists(audio_path):\n",
    "                duration = librosa.get_duration(path=audio_path)\n",
    "                total_duration += duration\n",
    "    \n",
    "    avg_duration = total_duration / min(100, len(lines))\n",
    "    estimated_total = avg_duration * len(lines) / 60  # in minutes\n",
    "    \n",
    "    print(f\"   Estimated duration: {estimated_total:.1f} minutes\")\n",
    "    print(f\"   Average clip length: {avg_duration:.2f} seconds\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nüìù Sample entries:\")\n",
    "    for i, line in enumerate(lines[:5]):\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) >= 2:\n",
    "            print(f\"   {i+1}. {parts[1][:50]}...\")\n",
    "    \n",
    "    # Play first audio sample\n",
    "    print(\"\\nüîä Playing first audio sample:\")\n",
    "    first_audio = f\"kurdish_data/{lines[0].strip().split('|')[0]}\"\n",
    "    if os.path.exists(first_audio):\n",
    "        display(Audio(first_audio))\n",
    "    \n",
    "    print(\"\\n‚úÖ Dataset verified successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå metadata.csv not found! Please upload your metadata file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## ‚öôÔ∏è Step 6: Configure Training Parameters\n",
    "\n",
    "Set up the training configuration for Coqui TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configure-training"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    \"model\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "    \"dataset_path\": \"kurdish_data\",\n",
    "    \"output_path\": \"kurdish_tts_model\",\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 1000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"language\": \"ku\",\n",
    "    \"audio_sample_rate\": 16000,\n",
    "    \"text_cleaner\": \"multilingual_cleaners\",\n",
    "    \"use_gpu\": True\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "with open('training_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"‚öôÔ∏è Training Configuration:\")\n",
    "print(json.dumps(config, indent=2))\n",
    "print(\"\\n‚úÖ Configuration saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-header"
   },
   "source": [
    "## üéØ Step 7: Initialize TTS Model\n",
    "\n",
    "Load the pre-trained XTTS v2 model. This model already supports Kurdish!\n",
    "\n",
    "**Note:** XTTS v2 is pre-trained on Kurdish data from Mozilla Common Voice, so you can use it directly or fine-tune it with your own voice samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start-training"
   },
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "import torch\n",
    "\n",
    "# Check CUDA availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "# Initialize TTS model\n",
    "print(\"üì• Loading XTTS v2 model... (this may take a few minutes)\")\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(\"\\nüí° XTTS v2 is pre-trained on Kurdish data.\")\n",
    "print(\"For custom voices, use voice cloning with a reference speaker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test-model-header"
   },
   "source": [
    "## üß™ Step 8: Test the Model\n",
    "\n",
    "Generate speech samples using the pre-trained model or your custom voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-model"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "# Test sentences in Kurdish\n",
    "test_sentences = [\n",
    "    \"Silav, tu √ßawa y√Æ?\",\n",
    "    \"Ez bi x√™r im, spas!\",\n",
    "    \"Nav√™ min Ahmed e.\",\n",
    "    \"Ez ji Kurdistan√™ me.\",\n",
    "    \"√ävara te bi x√™r.\"\n",
    "]\n",
    "\n",
    "print(\"üé§ Generating speech samples...\\n\")\n",
    "\n",
    "# Option 1: Use pre-trained voice (no reference needed)\n",
    "use_reference = input(\"Use custom reference voice? (y/n): \")\n",
    "\n",
    "reference_audio = None\n",
    "if use_reference.lower() == 'y':\n",
    "    # Use your uploaded audio as reference\n",
    "    reference_audio = \"kurdish_data/wavs_processed/audio_001.wav\"\n",
    "    print(f\"Using reference audio: {reference_audio}\\n\")\n",
    "\n",
    "for i, text in enumerate(test_sentences, 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "    \n",
    "    # Generate audio\n",
    "    output_path = f\"test_output_{i}.wav\"\n",
    "    \n",
    "    try:\n",
    "        if reference_audio and os.path.exists(reference_audio):\n",
    "            # Use voice cloning with reference audio\n",
    "            tts.tts_to_file(\n",
    "                text=text,\n",
    "                file_path=output_path,\n",
    "                speaker_wav=reference_audio,\n",
    "                language=\"ku\"\n",
    "            )\n",
    "        else:\n",
    "            # Use pre-trained voice\n",
    "            tts.tts_to_file(\n",
    "                text=text,\n",
    "                file_path=output_path,\n",
    "                language=\"ku\"\n",
    "            )\n",
    "        \n",
    "        # Play audio\n",
    "        display(Audio(output_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Test samples generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-header"
   },
   "source": [
    "## üì¶ Step 9: Export and Download Model\n",
    "\n",
    "Package your model configuration for use on Raspberry Pi or local server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-model"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "from datetime import datetime\n",
    "\n",
    "# Create export directory\n",
    "export_dir = \"kurdish_tts_export\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Copy reference audio for voice cloning (if used)\n",
    "if reference_audio and os.path.exists(reference_audio):\n",
    "    shutil.copy(reference_audio, f\"{export_dir}/reference_speaker.wav\")\n",
    "    print(\"‚úÖ Reference audio copied\")\n",
    "\n",
    "# Copy test outputs\n",
    "for i in range(1, 6):\n",
    "    test_file = f\"test_output_{i}.wav\"\n",
    "    if os.path.exists(test_file):\n",
    "        shutil.copy(test_file, f\"{export_dir}/{test_file}\")\n",
    "print(\"‚úÖ Test outputs copied\")\n",
    "\n",
    "# Create usage instructions\n",
    "instructions = f\"\"\"# Kurdish TTS Model - Usage Instructions\n",
    "\n",
    "## Installation\n",
    "```bash\n",
    "pip install TTS>=0.27.0\n",
    "```\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Initialize model\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "\n",
    "# Generate speech with your custom voice (if reference_speaker.wav is included)\n",
    "tts.tts_to_file(\n",
    "    text=\"Silav, tu √ßawa y√Æ?\",\n",
    "    file_path=\"output.wav\",\n",
    "    speaker_wav=\"reference_speaker.wav\",\n",
    "    language=\"ku\"\n",
    ")\n",
    "\n",
    "# Or use the pre-trained voice (no reference needed)\n",
    "tts.tts_to_file(\n",
    "    text=\"Silav, tu √ßawa y√Æ?\",\n",
    "    file_path=\"output.wav\",\n",
    "    language=\"ku\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Integration with TTS_STT_Kurdifer\n",
    "1. Install: pip install -r requirements.txt\n",
    "2. Copy reference_speaker.wav to your project directory (optional)\n",
    "3. Update tts_stt_service_base44.py to use the reference speaker\n",
    "4. Test with: python tts_stt_service_base44.py\n",
    "\n",
    "## Model Details\n",
    "- Model: XTTS v2 (Multilingual)\n",
    "- Language: Kurdish (ku)\n",
    "- Pre-trained: Yes (on Mozilla Common Voice Kurdish dataset)\n",
    "- Voice Cloning: Supported (optional)\n",
    "\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{export_dir}/README.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(instructions)\n",
    "\n",
    "# Create archive\n",
    "print(\"\\nüì¶ Creating export package...\")\n",
    "shutil.make_archive('kurdish_tts_model', 'zip', export_dir)\n",
    "\n",
    "print(\"‚úÖ Model exported successfully!\")\n",
    "print(\"\\nüì• Downloading model package...\")\n",
    "\n",
    "# Download the package\n",
    "files.download('kurdish_tts_model.zip')\n",
    "\n",
    "print(\"\\n‚úÖ Download complete!\")\n",
    "print(\"\\nüìù Next steps:\")\n",
    "print(\"1. Extract the ZIP file\")\n",
    "print(\"2. Read README.txt for usage instructions\")\n",
    "print(\"3. Integrate with your TTS_STT_Kurdifer project\")\n",
    "print(\"4. Test on your Raspberry Pi or local server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips-header"
   },
   "source": [
    "## üí° Tips for Better Results\n",
    "\n",
    "### Data Quality\n",
    "- Use clear, noise-free recordings\n",
    "- Consistent speaking pace and volume\n",
    "- Diverse vocabulary and sentence structures\n",
    "- At least 30 minutes of audio (more is better)\n",
    "\n",
    "### Voice Cloning Best Practices\n",
    "- Choose a reference audio with clear pronunciation\n",
    "- 3-10 seconds is optimal length for reference\n",
    "- Avoid background noise in reference audio\n",
    "- Can use multiple reference speakers for variety\n",
    "- Test different reference samples to find the best one\n",
    "\n",
    "### Performance Tips\n",
    "- First generation takes longer (model initialization)\n",
    "- Subsequent generations are faster (model cached)\n",
    "- GPU recommended for production use\n",
    "- CPU works but is slower\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [Coqui TTS Documentation](https://docs.coqui.ai/en/latest/)\n",
    "- [XTTS v2 Model Card](https://huggingface.co/coqui/XTTS-v2)\n",
    "- [Mozilla Common Voice Kurdish](https://commonvoice.mozilla.org/ku)\n",
    "- [TTS_STT_Kurdifer Repository](https://github.com/T1Agit/TTS_STT_Kurdifer)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for the Kurdish community**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
