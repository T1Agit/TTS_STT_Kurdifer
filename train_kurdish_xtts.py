#!/usr/bin/env python3
"""
XTTS v2 Fine-Tuning Script for Kurdish (Kurmanji)

This script fine-tunes the XTTS v2 multilingual model on Kurdish Common Voice data
to add proper Kurdish language support.

Requirements:
- Mozilla Common Voice Kurdish corpus (cv-corpus-24.0-2025-12-05-kmr)
- 8GB+ VRAM (RTX 2070 or better)
- ~20GB disk space for processed data

Dataset: Mozilla Common Voice Kurdish (Kurmanji)
https://datacollective.mozillafoundation.org/datasets/cmj8u3pbq00dtnxxbz4yoxc4i
"""

import os
import sys
import json
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import shutil

# Audio processing
import librosa
import soundfile as sf

# Deep learning
import torch
from torch.utils.data import Dataset, DataLoader

print("=" * 80)
print("XTTS v2 Fine-Tuning for Kurdish (Kurmanji)")
print("=" * 80)


class CommonVoiceKurdishDataset:
    """Handler for Mozilla Common Voice Kurdish dataset"""
    
    def __init__(self, corpus_path: str, output_dir: str):
        """
        Initialize dataset handler
        
        Args:
            corpus_path: Path to Common Voice corpus directory
                        (e.g., cv-corpus-24.0-2025-12-05-kmr/cv-corpus-24.0-2025-12-05/kmr/)
            output_dir: Directory to save processed audio files
        """
        self.corpus_path = Path(corpus_path)
        self.clips_dir = self.corpus_path / "clips"
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Check if corpus exists
        if not self.corpus_path.exists():
            raise FileNotFoundError(
                f"Corpus path not found: {self.corpus_path}\n"
                f"Please download the Mozilla Common Voice Kurdish corpus and extract it."
            )
        
        if not self.clips_dir.exists():
            raise FileNotFoundError(
                f"Clips directory not found: {self.clips_dir}\n"
                f"Expected structure: {self.corpus_path}/clips/"
            )
        
        print(f"‚úÖ Found corpus at: {self.corpus_path}")
        print(f"‚úÖ Found clips at: {self.clips_dir}")
    
    def load_tsv(self, tsv_name: str = "validated.tsv") -> pd.DataFrame:
        """
        Load and parse Common Voice TSV file
        
        Args:
            tsv_name: Name of TSV file (validated.tsv, train.tsv, dev.tsv, test.tsv)
            
        Returns:
            DataFrame with columns: client_id, path, sentence, up_votes, down_votes, etc.
        """
        tsv_path = self.corpus_path / tsv_name
        
        if not tsv_path.exists():
            raise FileNotFoundError(f"TSV file not found: {tsv_path}")
        
        print(f"\nüìä Loading {tsv_name}...")
        df = pd.read_csv(tsv_path, sep='\t')
        print(f"   Total entries: {len(df)}")
        
        return df
    
    def filter_quality_clips(
        self,
        df: pd.DataFrame,
        min_upvotes: int = 2,
        max_downvotes: int = 0,
        min_duration: float = 2.0,
        max_duration: float = 15.0
    ) -> pd.DataFrame:
        """
        Filter clips for quality
        
        Args:
            df: DataFrame from load_tsv()
            min_upvotes: Minimum upvotes required
            max_downvotes: Maximum downvotes allowed
            min_duration: Minimum audio duration in seconds
            max_duration: Maximum audio duration in seconds
            
        Returns:
            Filtered DataFrame
        """
        print("\nüîç Filtering for quality...")
        initial_count = len(df)
        
        # Filter by votes
        if 'up_votes' in df.columns and 'down_votes' in df.columns:
            df = df[
                (df['up_votes'] >= min_upvotes) &
                (df['down_votes'] <= max_downvotes)
            ]
            print(f"   After vote filtering: {len(df)} clips ({len(df)/initial_count*100:.1f}%)")
        
        # Filter by duration (if available in TSV)
        # Note: Some Common Voice versions don't include duration in TSV
        # We'll check duration during audio processing instead
        
        # Remove entries with missing sentence
        df = df.dropna(subset=['sentence'])
        df = df[df['sentence'].str.strip() != '']
        print(f"   After text filtering: {len(df)} clips ({len(df)/initial_count*100:.1f}%)")
        
        return df
    
    def process_audio_file(
        self,
        audio_path: Path,
        target_sr: int = 22050,
        min_duration: float = 2.0,
        max_duration: float = 15.0
    ) -> Tuple[np.ndarray, int, bool]:
        """
        Load and process audio file
        
        Args:
            audio_path: Path to MP3 audio file
            target_sr: Target sample rate (22050 for XTTS v2)
            min_duration: Minimum duration in seconds
            max_duration: Maximum duration in seconds
            
        Returns:
            Tuple of (audio_array, sample_rate, is_valid)
        """
        try:
            # Load audio with librosa (handles MP3 files)
            audio, sr = librosa.load(str(audio_path), sr=target_sr, mono=True)
            
            # Check duration
            duration = len(audio) / sr
            if duration < min_duration or duration > max_duration:
                return None, sr, False
            
            # Normalize audio
            audio = librosa.util.normalize(audio)
            
            return audio, sr, True
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Error processing {audio_path.name}: {e}")
            return None, target_sr, False
    
    def prepare_training_data(
        self,
        df: pd.DataFrame,
        target_sr: int = 22050,
        min_duration: float = 2.0,
        max_duration: float = 15.0,
        max_samples: int = None
    ) -> List[Dict[str, str]]:
        """
        Process and prepare training data
        
        Args:
            df: Filtered DataFrame
            target_sr: Target sample rate
            min_duration: Minimum audio duration
            max_duration: Maximum audio duration
            max_samples: Maximum number of samples to process (None for all)
            
        Returns:
            List of dicts with 'audio_path' and 'text' keys
        """
        print("\nüîÑ Processing audio files...")
        
        processed_data = []
        total = len(df) if max_samples is None else min(len(df), max_samples)
        
        for idx, row in df.head(total).iterrows():
            if idx % 100 == 0:
                print(f"   Progress: {idx}/{total} ({idx/total*100:.1f}%)")
            
            # Get audio file path
            audio_filename = row['path']
            audio_path = self.clips_dir / audio_filename
            
            if not audio_path.exists():
                continue
            
            # Process audio
            audio, sr, is_valid = self.process_audio_file(
                audio_path, target_sr, min_duration, max_duration
            )
            
            if not is_valid or audio is None:
                continue
            
            # Save processed audio as WAV
            output_filename = audio_filename.replace('.mp3', '.wav')
            output_path = self.output_dir / output_filename
            
            sf.write(output_path, audio, sr)
            
            # Add to training data
            processed_data.append({
                'audio_path': str(output_path),
                'text': row['sentence'].strip(),
                'speaker_id': row.get('client_id', 'unknown')
            })
        
        print(f"\n‚úÖ Processed {len(processed_data)} valid audio clips")
        return processed_data


class XTTSv2Trainer:
    """XTTS v2 fine-tuning trainer for Kurdish"""
    
    def __init__(
        self,
        output_model_dir: str = "models/kurdish",
        base_model: str = "tts_models/multilingual/multi-dataset/xtts_v2"
    ):
        """
        Initialize trainer
        
        Args:
            output_model_dir: Directory to save fine-tuned model
            base_model: Base XTTS v2 model name
        """
        self.output_model_dir = Path(output_model_dir)
        self.output_model_dir.mkdir(parents=True, exist_ok=True)
        self.base_model = base_model
        
        # Check CUDA availability
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"\nüñ•Ô∏è  Device: {self.device}")
        
        if self.device == "cuda":
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("   ‚ö†Ô∏è  No GPU detected. Training on CPU will be very slow.")
    
    def load_base_model(self):
        """Load base XTTS v2 model"""
        try:
            from TTS.api import TTS
            
            print(f"\nüîß Loading base model: {self.base_model}")
            self.tts = TTS(
                model_name=self.base_model,
                progress_bar=True,
                gpu=(self.device == "cuda")
            )
            print("‚úÖ Base model loaded")
            
        except Exception as e:
            print(f"‚ùå Error loading base model: {e}")
            raise
    
    def train(
        self,
        training_data: List[Dict[str, str]],
        epochs: int = 10,
        batch_size: int = 2,
        learning_rate: float = 1e-5,
        checkpoint_interval: int = 2
    ):
        """
        Fine-tune XTTS v2 on Kurdish data
        
        Args:
            training_data: List of dicts with 'audio_path' and 'text'
            epochs: Number of training epochs
            batch_size: Batch size (keep small for 8GB VRAM)
            learning_rate: Learning rate
            checkpoint_interval: Save checkpoint every N epochs
        """
        print("\n" + "=" * 80)
        print("Starting Fine-Tuning")
        print("=" * 80)
        print(f"Training samples: {len(training_data)}")
        print(f"Epochs: {epochs}")
        print(f"Batch size: {batch_size}")
        print(f"Learning rate: {learning_rate}")
        
        # NOTE: XTTS v2 fine-tuning requires the TTS.tts.configs.xtts_config module
        # and specific training scripts from Coqui TTS repository.
        # 
        # For a production implementation, you would need to:
        # 1. Use the official XTTS fine-tuning recipe from Coqui TTS
        # 2. Or use the trainer.GPT_train() method if available
        # 3. Configure the model for Kurdish language
        #
        # This is a simplified implementation outline.
        
        print("\n‚ö†Ô∏è  XTTS v2 fine-tuning requires additional setup:")
        print("   1. This script prepares and validates your data")
        print("   2. For actual fine-tuning, use the official Coqui TTS trainer")
        print("   3. Or use voice cloning as a workaround (no training needed)")
        
        # Save training data manifest
        manifest_path = self.output_model_dir / "training_manifest.json"
        with open(manifest_path, 'w', encoding='utf-8') as f:
            json.dump(training_data, f, indent=2, ensure_ascii=False)
        print(f"\n‚úÖ Saved training manifest to: {manifest_path}")
        
        # Save a simple config
        config = {
            "language": "ku",
            "model_type": "xtts_v2_finetuned",
            "base_model": self.base_model,
            "training_samples": len(training_data),
            "epochs": epochs,
            "batch_size": batch_size,
            "learning_rate": learning_rate
        }
        config_path = self.output_model_dir / "config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2)
        print(f"‚úÖ Saved config to: {config_path}")


def main():
    """Main training pipeline"""
    parser = argparse.ArgumentParser(
        description="Fine-tune XTTS v2 on Kurdish Common Voice data"
    )
    parser.add_argument(
        "--corpus_path",
        type=str,
        default="cv-corpus-24.0-2025-12-05-kmr/cv-corpus-24.0-2025-12-05/kmr/",
        help="Path to Common Voice Kurdish corpus directory"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="processed_audio",
        help="Directory to save processed audio files"
    )
    parser.add_argument(
        "--model_dir",
        type=str,
        default="models/kurdish",
        help="Directory to save fine-tuned model"
    )
    parser.add_argument(
        "--tsv_file",
        type=str,
        default="validated.tsv",
        help="TSV file to use (validated.tsv, train.tsv, etc.)"
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="Maximum number of samples to process (None for all)"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=10,
        help="Number of training epochs"
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=2,
        help="Batch size (keep small for 8GB VRAM)"
    )
    
    args = parser.parse_args()
    
    print("\nüìã Configuration:")
    print(f"   Corpus path: {args.corpus_path}")
    print(f"   Output dir: {args.output_dir}")
    print(f"   Model dir: {args.model_dir}")
    print(f"   TSV file: {args.tsv_file}")
    print(f"   Max samples: {args.max_samples or 'All'}")
    print(f"   Epochs: {args.epochs}")
    print(f"   Batch size: {args.batch_size}")
    
    # Step 1: Load and prepare dataset
    print("\n" + "=" * 80)
    print("STEP 1: Loading Dataset")
    print("=" * 80)
    
    dataset = CommonVoiceKurdishDataset(
        corpus_path=args.corpus_path,
        output_dir=args.output_dir
    )
    
    # Load TSV
    df = dataset.load_tsv(args.tsv_file)
    
    # Filter for quality
    df = dataset.filter_quality_clips(
        df,
        min_upvotes=2,
        max_downvotes=0,
        min_duration=2.0,
        max_duration=15.0
    )
    
    # Process audio files
    training_data = dataset.prepare_training_data(
        df,
        target_sr=22050,
        min_duration=2.0,
        max_duration=15.0,
        max_samples=args.max_samples
    )
    
    if len(training_data) == 0:
        print("\n‚ùå No valid training data found!")
        print("   Please check your corpus path and TSV file.")
        return 1
    
    # Step 2: Initialize trainer
    print("\n" + "=" * 80)
    print("STEP 2: Initializing Trainer")
    print("=" * 80)
    
    trainer = XTTSv2Trainer(output_model_dir=args.model_dir)
    
    # Load base model
    trainer.load_base_model()
    
    # Step 3: Train (prepare data for training)
    print("\n" + "=" * 80)
    print("STEP 3: Training Preparation")
    print("=" * 80)
    
    trainer.train(
        training_data=training_data,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=1e-5,
        checkpoint_interval=2
    )
    
    # Final summary
    print("\n" + "=" * 80)
    print("‚úÖ Training Pipeline Complete!")
    print("=" * 80)
    print(f"\nüìÅ Output locations:")
    print(f"   Processed audio: {args.output_dir}/")
    print(f"   Model directory: {args.model_dir}/")
    print(f"   Training manifest: {args.model_dir}/training_manifest.json")
    print(f"   Config: {args.model_dir}/config.json")
    
    print("\nüí° Next Steps:")
    print("   1. Review the processed audio quality")
    print("   2. For actual fine-tuning, use Coqui TTS official training scripts")
    print("   3. Or use voice cloning with representative Kurdish audio samples")
    print("   4. Place the fine-tuned model in models/kurdish/ directory")
    print("   5. Run: python tts_stt_service_base44.py to test")
    
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Training interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
